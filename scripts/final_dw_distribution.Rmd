---
title: "final_dw_distribution"
author: "abbey yatsko"
date: "7/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# SERC deadwood project
### script topic: deadwood survey exploration
deadwood >10cm from the forestGEO plot at SERC was surveyed over three time points (2014, 2017, 2021). for each survey, collected information varied, including the metrics / measurement scale for decay class. for example, decay class was measured as a 3-tiered variable in 2014, and 5-tiered variable in 2017 and 2021. based on classification descriptions from each protocol, the 5-tiered scale can be translated and broken down into that of the 3-tiered scale. this will be necessary to do when making tri-year comparisons of decay stage.  

additional metrics measured include: DBH, log/snag, height/length, top diameters (for downed pieces), air/ground contact, position within subplots, A/B/C pieces (for fragments) and so on... some of these variables also changed across years. of greatest interest are the dimensional measurements, decay class, species, and then differentiation between snags and logs.

following the 2021 survey, data comes from four sources: 
  * dead_2019.csv
  * living_2019.csv
  * deadwood_2014.csv
  * deadwood_2017.csv 

the goal of the study is to track pieces that cover all three time points of the survey and then sample these pieces for microbes/ C gas fluxes. the goal of this script is to parse through how dw distributions looked at each timepoint, and also how individual pieces move through 'the system' in time 

#### 1. ORGANIZE WORKSPACE----
```{r workspace}
# libraries
library(ggplot2)
library(ggpubr)
library(dplyr)
library(tidyverse)

# FUNCTIONS
# consolidate (function)
# function for populating a single column which is techincally the 4 repeated variables merged together 
consolidate <- function(df){ # c.name is the target name 
  new.col <- rep(NA, length = nrow(df))
  for (i in 1:nrow(df)){
    not.na <- which(!is.na(df[i, ]))
    n.val <- length(not.na)
    new.col[i] <- ifelse(n.val != 0, df[i, not.na[1]], NA)
  }
  return(new.col)
}

# expand.dataframe (function)
# function for picking out variables that draw from 4 original dataframes (dw2014, dw2017, dead_2019, living_2019) and then create problematic .x, .y, .x.x, .y.y variables (example: DC.2021.x, DC.2021.y, DC.2021.x.x, DC.2021.y.y). the goal here is to merge the .x, .y etc. variables of the same category into a 'master' variable the converges all 4 values (example of what we want in the end: DC.2021). note that this phenomenon is observed for variables added under the 2021 survey.
df <- dw_total
expand.dataframe <-  function(new.df, df, NAME){
  name.cols <- grep(NAME, names(df))
  prob.cols <- grep(paste(NAME, "2021", sep = "."), names(df))
  new.df <- cbind(new.df, df[,setdiff(name.cols, prob.cols)])
  new.col <- consolidate(df[,prob.cols])
  assign(paste(NAME, "2021", sep = "."), new.col)
  new.df <- cbind(new.df, new.col)
  names(new.df)[names(new.df) == "new.col"] <- paste(NAME, "2021", sep = ".")
  return(new.df)
} 

# expand_dataframe_SP (function)
# resolve SPCODE merge error 
expand.dataframe_SP <-  function(new.df, df, NAME = "SPCODE"){
  prob.cols <- grep("SPCODE", names(df))
  new.col <- consolidate(df[,prob.cols])
  new.df <- cbind(new.df, new.col)
  names(new.df)[names(new.df) == "new.col"] <- "SPCODE"
  return(new.df)
} 

# all_na (function)
# use this function to remove any column that is completely populated by NAs (indicates a data-less column that is not of particular use!)
all_na <- function(x) any(!is.na(x))

# set working directory 
# setwd("C:/Users/ary24/Desktop/repos/serc_deadwood/FINAL_DATA") # for lab server workflow
setwd("/Users/abbeyyatsko/Desktop/repos/serc_deadwood/FINAL_DATA") #for macbook workflow 

# read in data 
dw2014 <- read.csv("deadwood_2014.csv", na.strings=c("","NA"))
dw2017 <- read.csv("deadwood_2017.csv", na.strings=c("","NA"))
dead_2019 <- read.csv("dead_2019.csv", na.strings=c("","NA"))
living_2019 <- read.csv("living_2019.csv", na.strings=c("","NA"))
```

note the initial length of the dataframes
  * 2014 has 1371 observations
  * 2017 has 682 observations (approximately half of the preceding survey)
  * dead_2019 has 460 observations
  * living_2019 has 4662 observations (most of these are going to be living trees, of which a handful had died and then moved into the           deadwood pool during the 2021 survey)

#### 2. EXPLORE DATA: dw2014 ----
```{r explore data dw2014}
dw2014 %>% summarise_all(n_distinct)
# 6 columns have only 1 unique value - these are filled with NAs. therefore, delete these rows all together, as they contain no information for us (just to simplify the dataset)
# therefore, get rid of columns that are completely empty

dw2014 <- dw2014 %>% select_if(all_na)
# 6 removed columns specifically include: STEMTAG, SPOCDE, QX, QY, HEIGHT.2021, ANGLE
# dimensions are now 1371 observations of 19 variables 

# next step is to change TAG --> STEMTAG (to keep them the same across all 3 surveys, as this will be the link across all data frames for the merge)
dw2014 <- rename(dw2014, STEMTAG=TAG)

# rename Breakdownstatus.2014 --> BDS.2014
dw2014 <- rename(dw2014, BDS.2014=BREAKDOWNSTATUS.2014)

# rename decay class column to indicate year 2014
dw2014 <- rename(dw2014, DC.2014=DECAYCLASSORIG)

# rename decay class column to indicate year 2021 and include new abbreviation  
dw2014 <- rename(dw2014, DC.2021=DECAYCLASS.2021)

# rename DBH to indicate year 2014
dw2014 <- rename(dw2014, DBH.2014=DBH)

# drop direction column - only one val recorded and I think this was right at the beginning of the 2021 resurvey (we did not end up recording this across the 2021 survey)
dw2014 <- select(dw2014, -DIRECTION)

```

#### 3. EXPLORE DATA: dw2017 ----
```{r explore data dw2017}
dw2017 %>% summarise_all(n_distinct)
# looks like the X, X.1, X.2, X.3 variables are just empty with NAs. therefore, choose to remove these blank data columns - should reduce dimensions to 40 variables 
dw2017 <- dw2017 %>% select_if(all_na)
# good 

# rename Breakdownstatus.2017 --> BDS.2017
dw2017 <- rename(dw2017, BDS.2017=BREAKDOWNSTATUS.2017)

# rename decay class column to indicate year 2017 and include new abbreviation  
dw2017 <- rename(dw2017, DC.2017=DECAYCLASS.2017)

# get rid of DECAYCLASSORIG since it is the 'translated' version of DC.2017 from a 5-tier to a 3-tier decay classification system. this will be onboarded in later steps 
dw2017 <- select(dw2017, -DECAYCLASSORIG)

# rename decay class column to indicate year 2021 and include new abbreviation  
dw2017 <- rename(dw2017, DC.2021=DECAYCLASS.2021)

# QUESTION - what is the DBH column referring to? I don't think it matches up to 2014... leaving as is for now. TASK - assign meaning to this variable within the context of all surveys 

# drop direction and angle column - only one val recorded (ANGLE) and 9 in DIRECTION, we recorded this a few times at the beginning of the 2021 survey but then dropped it because the information was not deemed useful for my bigger picture decay class questions
dw2017 <- select(dw2017, -DIRECTION, -ANGLE)

# last few columns - I don't really know what these ones mean
# listed: LG.END.DIAM SM.END.DIAM LG.PX LG.PY SM.PX SM.PY CORRXTREE CORRYTREE UTMX_TREES UTMY_TREES
# keep for now, but note clutter
```

#### 4. EXPLORE DATA: dead_2019 ----
essentially what we have in this dataframe is a bunch of individuals that were dead in 2019. in the dw survey for 2021, we did not pick every last one of these up (visual inspection of spreadsheet). however, when new pieces were added to this, we recorded BDS, decay class, and dimensional measurements. all other observations may be coming from 2017 and 2014 surveys. 

```{r explore data dead_2019}
dead_2019 %>% summarise_all(n_distinct)
# only one column (ANGLE) without any content (only NAs). therefore, this will be pulled out. 
dead_2019 <- dead_2019 %>% select_if(all_na)
# good 

# QUESTION - what is the DBH column referring to? similar question to what shows up in dw2017... leaving as is for now. TASK - assign meaning to this variable within the context of all surveys 
  # maybe this is the DBH that corresponds to 2019? check on this

# rename integrity.2021 --> integ (to keep consistent across data sets)
dead_2019 <- rename(dead_2019, INTEG.2021=INTEGRITY.2021)

# rename decay class column to indicate year 2021 and include new abbreviation  
dead_2019 <- rename(dead_2019, DC.2021=DECAYCLASS.2021)

# rename length column to indicate year 2021 
dead_2019 <- rename(dead_2019, LENGTH.2021=LENGTH)

# cut out direction - we recorded this a few times at the beginning of the 2021 survey but then dropped it because the information was not deemed useful for my bigger picture decay class questions
dead_2019 <- select(dead_2019, -DIRECTION)
```

#### 5. EXPLORE DATA: living_2019 ----
for this one, the majority of observations are actually for live things. therefore, we only want to pull out what we added in the 2021 dw survey, i.e. things that had died since the demography survey in 2019. these entries are indicated via those with BDS, decay class, any .2021 data essentially. let's filter to begin with by pulling out only stemtags that have a recorded value for BDS.2021 

```{r explore data living_2019}
# filter out living stems (those in which no info was recorded for in the 2021 dw survey). select for those samples that have recorded values for BDS.2021
living_2019 <- living_2019 %>%                                       
  filter(!is.na(BDS.2021)) 
# now what we have is all of the new recruits of dw since the 2019 survey 

living_2019 %>% summarise_all(n_distinct)
# looks like it makes sense to drop angle and direction again - do this in a few lines to keep things in order 

# rename integrity.2021 --> integ (to keep consistent across data sets)
living_2019 <- rename(living_2019, INTEG.2021=INTEGRITY.2021)

# rename decay class column to indicate year 2021 and include new abbreviation  
living_2019 <- rename(living_2019, DC.2021=DECAYCLASS.2021)

# rename length column to indicate year 2021 
living_2019 <- rename(living_2019, LENGTH.2021=LENGTH)

# drop direction and angle column - all NAs
living_2019 <- select(living_2019, -DIRECTION, -ANGLE)
```

now we should have all our data in a more meaningful, managable, and consistent form (when it comes to variables especially). here they are:

```{r list polished data frames}
View(dw2014)
View(dw2017)
View(dead_2019)
View(living_2019) # dead within the living 2019 survey - so techincally all these pieces are actually dead and not living 
```

QUESTION: 
from dw_2014 should we remove rows that are recorded with 'no tag' for the stemtag variable? having no stem tag is not useful for tracking individual pieces thru time, but could be helpful for overall biomass estimates (especially if some of these no-taggers are big trees that died prior to forestGEO censusing - representing large C sinks thru biomass, even if untracked/unidentifiable at the species level)
  * ask about coordinates for 2014 dw data 
  * for the time being, let's get rid of 'no tag' stems from 2014 but possibly circle back

```{r fix no stemtag}
# get rid of things wihtout a stemtag 
dw2014 <- subset(dw2014, STEMTAG != "no tag")
dw2017 <- subset(dw2017, STEMTAG != "NA")

# merge stemtag and piece for new identifier -> PIECETAG
# dw2014 
sum(is.na(dw2014$PIECE.2014)) # no NAs in the piece vector
dw2014$PIECETAG <- paste(dw2014$STEMTAG, dw2014$PIECE.2014, sep = "")

# dw2017
sum(is.na(dw2017$PIECE.2017)) # 60 NAs in the piece vector 
# where there are NAs, we are now putting in piece = "A" such that the PIECETAG identifier makes sense (for example: 101A vs. 101NA)
dw2017$PIECE.2017 <- ifelse(is.na(dw2017$PIECE.2017), "A", dw2017$PIECE.2017)
dw2017$PIECETAG <- paste(dw2017$STEMTAG, dw2017$PIECE.2017, sep = "")

# dead_2019
sum(is.na(dead_2019$PIECE.2021)) # 322 NAs in the piece vector 
dead_2019$PIECE.2021 <- ifelse(is.na(dead_2019$PIECE.2021), "A", dead_2019$PIECE.2021)
dead_2019$PIECETAG <- paste(dead_2019$STEMTAG, dead_2019$PIECE.2021, sep = "")

# living_2019 
which(is.na(living_2019$PIECE.2021)) # 18 NAs in the piece vector 
living_2019$PIECE.2021 <- ifelse(is.na(living_2019$PIECE.2021), "A", living_2019$PIECE.2021)
living_2019$PIECETAG <- paste(living_2019$STEMTAG, living_2019$PIECE.2021, sep = "")
```

#### 6. MERGING DATA ----
the next goal would be to merge all of the dataframes across the variable 'PIECETAG'. first we need to check out how the variable structure is being understood (make sure they are the same across all 4 sets)

```{r variable classes, results='hide'}
str(dw2014)
dw2014$QUADNAME <- as.factor(dw2014$QUADNAME)
dw2014$STEMTAG <- as.factor(dw2014$STEMTAG)
dw2014$DC.2014 <- as.factor(dw2014$DC.2014)
dw2014$DC.2021 <- as.factor(dw2014$DC.2021)
dw2014$TOPDIAM.2021 <- as.numeric(dw2014$TOPDIAM.2021)
dw2014$LENGTH.2014 <- as.numeric(dw2014$LENGTH.2014)
dw2014$PIECETAG <- as.factor(dw2014$PIECETAG)
dw2014$SPCODE <- as.character(dw2014$SPCODE)

str(dw2017)
dw2017$QUADNAME <- as.factor(dw2017$QUADNAME)
dw2017$TAG <- as.factor(dw2017$TAG)
dw2017$STEMTAG <- as.factor(dw2017$STEMTAG)
dw2017$DC.2017 <- as.factor(dw2017$DC.2017)
dw2017$DC.2021 <- as.factor(dw2017$DC.2021)
dw2017$PIECETAG <- as.factor(dw2017$PIECETAG)


str(dead_2019)
dead_2019$QUADNAME <- as.factor(dead_2019$QUADNAME)
dead_2019$TAG <- as.factor(dead_2019$TAG)
dead_2019$STEMTAG <- as.factor(dead_2019$STEMTAG)
dead_2019$INTEG.2021 <- as.character(dead_2019$INTEG.2021)
dead_2019$DC.2021 <- as.factor(dead_2019$DC.2021)
dead_2019$PIECETAG <- as.factor(dead_2019$PIECETAG)

str(living_2019)
living_2019$QUADNAME <- as.factor(living_2019$QUADNAME)
living_2019$TAG <- as.factor(living_2019$TAG)
living_2019$STEMTAG <- as.factor(living_2019$STEMTAG)
living_2019$DC.2021 <- as.factor(living_2019$DC.2021)
living_2019$PIECETAG <- as.factor(living_2019$PIECETAG)
```

prep data to merge - need to make sure that all of the columns that need to be 'shared' are included individually in each of the 4 merging datasets. 
 [1] "QUADNAME"     "STEMTAG"      "BDS.2021"     "PIECE.2021"   "INTEG.2021"   "DC.2021"     
 [7] "GC.2021"      "TOPDIAM.2021" "DBH.2021"     "LENGTH.2021" 

##### MERGE but with help - July 22 @ SERC

abbey: TASKS
  * pick key columns 
  * pick columns that we want disambiguigated 
  * look into cache = TRUE 
  
```{r prep merge with sean's help}
# full_join method - bringing together by PIECETAG 2 at a time 
# make a vector with 'base ID data' 
dw_total <- full_join(dw2014, dw2017, by = c("PIECETAG", "STEMTAG", "QUADNAME")) # list key things here in the c() 
dw_total <- full_join(dw_total, dead_2019, by = c("PIECETAG", "STEMTAG", "QUADNAME"))
dw_total <- full_join(dw_total, living_2019, by = c("PIECETAG", "STEMTAG", "QUADNAME"))

# the problem here is that things are duplicated (see DC.2021.x, DC.2021.y, etc.) -> we want this to merge under one variable, not multiple ones parsed out  

# quality controlling that repeated entries are the same across 4 replicated variables
# BDS.2021, PIECE.2021, INTEG.2021, DC.2021, GC.2021, TOPDIAM.2021, DBH.2021, LENGTH.2021, SPCODE, HEIGHT.2021

# VARIABLE.x, VARIABLE.y, VARIABLE.x.x, VARIABLE.y.y --> these four variables all represent the same 'baseline' variable, but since they are coming from 4 different original locations (dw2014, dw2017, dead_2019, living_2019), they are parsed seperately. the goal is to bring them all together into one single VARIABLE in the dw_total df 

# go through and check that for any of these 4 variables, if there are repeats across entries, make sure that the values are the same  

q.col <- grep("BDS.2021", names(dw_total))
names(dw_total)[q.col]
col.test <- apply(dw_total[,q.col], 1, function(x) length(which(!is.na(x))))
table(col.test)
# col.test
#   0   1   2 
# 806 761   2 
# this says that there are 806 samples with 0 entries for any version of BDS.2021, there are 761 samples that have one entry across the 4 versions of BDS.2021, and there are 2 samples that have 2 entries across the 4 versions of BDS.2021. what we need to do in the QUALITY CHECK is to make sure that for these 2 samples with 2 entries, there is agreement between them
head(dw_total[,q.col], 100)
# check and make sure that if there are more than 2 entries, they agree with one another in content 
dw_total[which(col.test == 2),q.col]
# this confirms the above question: are the duplicated entries the same across versions of the BDS.2021 variable?

# GOOD: BDS.2021, INTEG.2021, DC.2021, GC.2021, TOPDIAM.2021, DBH.2021, LENGTH.2021, SPCODE, HEIGHT.2021

# NOT GOOD: PIECE.2021 (maybe this isnt such a big deal since we have PIECETAG which is really what is of interest?)
# also SPCODE 

# for NOT GOOD: PIECE.2021
q.col <- grep("PIECE.2021", names(dw_total))
names(dw_total)[q.col]
col.test <- apply(dw_total[,q.col], 1, function(x) length(which(!is.na(x))))
table(col.test)
dw_total[which(col.test == 2),q.col]
# note that not all of the pieces are matching up 

p.index <- paste(dw_total$PIECE.2021.y, dw_total$PIECE.2021.x.x, sep = "")
# finding out what the duplicated piece value combos are - disregard NAs, pay attention to AA, BA, CA (see table below)
table(p.index)
dw_total[which(p.index == "BA"), c(grep("PIECE", names(dw_total)), grep("DBH", names(dw_total)))]

dw_total[which(p.index == "BA"),]
# what is happening here is there are dw pieces  from 2014 or 2017 (oftemtimes snags) where originally it is one piece, but then in 2021, the snag broke off and now has a snag AND a log piece. this matters because it captures the importance of the decay as things are fragmenting and turning into logs 
# pull out stemtags from dw_total[which(p.index == "BA"), c(grep("PIECE", names(dw_total)), grep("DBH", names(dw_total)))]
# note these later on if they need to be pulled out for sampling - representing a special case of decay where the nuance of the system is not captured with the code 

# for NOT GOOD: SPCODE
q.col <- grep("SPCODE", names(dw_total))
names(dw_total)[q.col]
col.test <- apply(dw_total[,q.col], 1, function(x) length(which(!is.na(x))))
table(col.test)
dw_total[which(col.test == 2),q.col]
# note that not all of the pieces are matching up - merge the two inner cols to see what is different and if they actually all match up 
s.index <- paste(dw_total$SPCODE.y, dw_total$SPCODE.x.x, sep = "")
# finding out what the duplicated piece value combos are - disregard NAs, pay attention to AA, BA, CA (see table below)
table(s.index)

# problem children are: FRPEFRAM2 (green ash/white ask) and there are only 2 of them so this could be a spot fix perhaps 
dw_total[which(s.index == "FRPEFRAM2"),]
# TO DO - send jess these two tags and ask her whats up and which sp we should go with  
# also maybe not the end of the world if we are not looking to sample ash trees at all 
```

```{r merge with sean's help}
# FOR THE REAL MERGE THING - a 4 step process that we must do 

# STEP 1 
# write out functions: 'expand.dataframe' and 'consolidate'
# DONE 
# see above in .rmd code chunk 2: setup 

# STEP 2
# create new dataframe with 'core columns' (non-problematic base data)
important.cols <- c("PIECETAG", "STEMTAG", "QUADNAME")
new.df <- dw_total[, important.cols]

# STEP 3
# select variables to correct and bind to new dataframe
name.list <- c("BDS", "DC", "TOPDIAM", "DBH", "LENGTH", "HEIGHT")
# the code breaks when GC and INTEG are included - therefore take out 

# STEP 4 
# first load functions (see below)

# for the SPCODE issue 
new.df <- expand.dataframe_SP(new.df, dw_total, "SPCODE")
head(new.df)

# for everything else that is important to us 
for (n in 1:length(name.list)) {
  new.df <- expand.dataframe(new.df, df = dw_total, name.list[n])
}
head(new.df)
head(dw_total)
# SPCODE - contributing from 3 sources and not 4 (dw2014 excludes a SPCODE record) - is this why it isn't merging together in step 4? 
# even after adding SPCODE to 2014, the probelm still persists. I think it is because the variable name 'SPCODE' does not actually include any .2021 tag, and this is what the function is looking for 


```

#### 7. LOOKING AT JUST DECAY CLASS ----
this is the next step for thinking about sampling. what do we want to measure, how should we choose pieces? 

goals for sampling: 
  * gas flux (LGR chamber measurements)
  * microbes (sawdust, CTAB, then sequencing)
  * also potentially some kind of moisture content (?)
  
considerations for sampling: 
  * in my grant proposals, I wanted to key into 1-2 species and then sample across all 5 decay classes 
  * search time could be a little intense - to sample, id be going out into forestGEO with quads and coordinates,       but it would still be a search process
  * right now, sawing out little cubes seems to be the best bet for subsampling logs. still up for debate is            multiple samples along the length of the log, if a single cube could be sufficient for flux, moisture content,      and also drilling for microbes 
  
what we are looking for in the dataframe:
  * samples that have DC for all 3 'timepoints' (?) (2014, 2017, 2021) -> 'complete cases'
    * alternatively, is it ok if there are measures for JUST 2014 and 2021, or JUST 2017 and 2021 -> 'partial cases'
  * we also should take a look at how many complete cases exist for the target species that we named (oak, QUERC and     tulip poplar, LITU) 
  
```{r subset decay class}
# from df.new: want PIECETAG, SPCODE, and then all records for DC across the 3 surveys 
dw_select <- new.df %>%
  select(c('STEMTAG', 'PIECETAG', 'SPCODE', 'DC.2014', 'DC.2017', 'DC.2021'))
# what kind of species are there?
unique(dw_select$SPCODE)

# what is the distribution of species counts? 
dw_select %>% 
        drop_na(SPCODE) %>%
        ggplot(aes(x = SPCODE))+
        geom_bar(stat="count")+
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# potential candidates:
  # tulip poplar (LITU) 
  # oaks (QUFA, QUERC, QUAL)
  # red maple (ACRU)
  # american beech (FAGR)
  # sweetgum (LIST2)

# SPECIES 1: LITU
# what is decay class distribution (2021) for all LITUs 
dw_LITU <- dplyr::filter(dw_select, SPCODE %in% c("LITU"))

# distribution of decay classes 
ggplot(dw_LITU, aes(x=DC.2021)) + geom_histogram()

# SPECIES 2: LIST2
# what is decay class distribution (2021) for all QURU 
dw_LIST2 <- dplyr::filter(dw_select, SPCODE %in% c("LIST2"))

# distribution of decay classes 
ggplot(dw_LIST2, aes(x=DC.2021)) + geom_histogram()

# PILOT DATA GOAL: sample at least 3 replicates from DC 1, 3, 5
# for pilot data sampling - pull from LITU and LIST2

pilot <- rbind(dw_LITU, dw_LIST2)
write.csv(pilot,"/Users/abbeyyatsko/Desktop/repos/serc_deadwood/FINAL_DATA/pilot.csv", row.names = FALSE)

pilot_stems <- pilot$PIECETAG
```









# blah blah blah 
# below things are notes from earlier times 

ok so if I did this right (let's pretend), we could theoretically start making sense of the data and doing some viz with it?? 
NOTE---but i dont think i actually did do it right so maybe we hold off with thinkin about this 

```{r initial viz}
# what kind of species are we working with? 
dw_merged %>% 
        drop_na(SPCODE) %>%
        ggplot(aes(x = SPCODE))+
        geom_bar(stat="count")+
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# lots of ash, sweetgum, tulip tree... think about what species to target here?

# what is the distribution of decay classes across 2014, 2017, and 2021? while also taking into account the different breakdown status... 

dc2014 <- ggplot(data = subset(dw_merged, !is.na(DC.2014)), aes(fill=BDS.2014, x=DC.2014)) + 
    geom_bar(position="stack", stat="count")

dc2017 <- ggplot(data = subset(dw_merged, !is.na(DC.2017)), aes(fill=BDS.2017, x=DC.2017)) + 
    geom_bar(position="stack", stat="count")

dc2021 <- ggplot(data = subset(dw_merged, !is.na(DC.2021)), aes(fill=BDS.2021, x=DC.2021)) + 
    geom_bar(position="stack", stat="count")

ggarrange(dc2014, dc2017, dc2021, nrow = 1)

# also look at DC distribution but now take into account species...  but just for 2017 and 2021 becuase theres not actually species data that is paired with the 2014 pieces 

dc2017_sp <- ggplot(data = subset(dw_merged, !is.na(DC.2017)), aes(fill=SPCODE, x=DC.2017)) + 
    geom_bar(position="stack", stat="count")

dc2021_sp <- ggplot(data = subset(dw_merged, !is.na(DC.2021)), aes(fill=SPCODE, x=DC.2021)) + 
    geom_bar(position="stack", stat="count")

ggarrange(dc2017_sp, dc2021_sp, nrow = 1)
```

#### 8. NEXT STEPS AND THINGS I WANT TO KNOW ----
  * need to pull out samples that account for the following transitions: 
    * 2014 -> 2017
    * 2014 -> 2017 -> 2021
    * 2014 -> 2021
  * thinking about transition matrix and how to actually code this 
  * make sure that the dw_merged dataframe is what I think it is 
  * best way to make rules for using dimensional measurements to construct biomass estimates? 
  
##### **THE BIG GOAL IS TO FIGURE OUT WHAT PIECES WE WANT TO TARGET FOR SUBSAMPLING C FLUX AND MICROBES!**

pull out only sample IDs and then decay classes across the three years 
```{r decay class dataframe}
dw_merged_dc <- dw_merged %>%
  select(c('STEMTAG', 'DC.2014', 'DC.2017', 'DC.2021'))


```


